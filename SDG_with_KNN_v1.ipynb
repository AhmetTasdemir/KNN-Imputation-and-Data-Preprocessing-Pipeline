{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMOOS3EaTI6-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ks_2samp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataset_insilico.csv')"
      ],
      "metadata": {
        "id": "CBIk2DCqW30d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "giLjkiEDXFsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = df.columns[3:]\n",
        "df_parameters = df[columns_to_keep]"
      ],
      "metadata": {
        "id": "-bo4DP_lXABS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_parameters.columns:\n",
        "    df_parameters[col] = df_parameters[col].astype(str).str.replace('%', '', regex=False)\n",
        "    df_parameters[col] = pd.to_numeric(df_parameters[col], errors='coerce') / 100.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9G-ipvqlXIPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('imputer', KNNImputer()),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "ZvoUNnZYXLGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'imputer__n_neighbors': [2, 3, 5, 7, 10],\n",
        "    'imputer__weights': ['uniform', 'distance'],\n",
        "    'imputer__metric': ['nan_euclidean', 'manhattan']\n",
        "}"
      ],
      "metadata": {
        "id": "0DHRjlyrXP4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(df_parameters)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zr0PkBf_XRtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(f\"Best hyperparameters: {best_params}\")"
      ],
      "metadata": {
        "id": "HPr4e66EY1L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled_scaled = pd.DataFrame(grid_search.best_estimator_.transform(df_parameters), columns=df_parameters.columns)"
      ],
      "metadata": {
        "id": "h2CnyXrdZgdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled_scaled"
      ],
      "metadata": {
        "id": "bw5xa3D7ZjAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_missing_values(data):\n",
        "    missing_values = data.isna().sum()\n",
        "    print(\"Missing Values After Imputation:\")\n",
        "    print(missing_values)\n",
        "    assert missing_values.sum() == 0, \"There are still missing values in the dataset!\"\n",
        "\n",
        "check_missing_values(df_filled_scaled)"
      ],
      "metadata": {
        "id": "sVah-8SKZk_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compare_distributions(original, imputed, column):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.histplot(original[column].dropna(), color='blue', label='Original', kde=True)\n",
        "    sns.histplot(imputed[column], color='orange', label='Imputed', kde=True)\n",
        "    plt.title(f'Distribution of {column} Before and After Imputation')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "for col in df_parameters.columns:\n",
        "    compare_distributions(df_parameters, df_filled_scaled, col)"
      ],
      "metadata": {
        "id": "kQ5kM2wZblz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_consistency(original, imputed):\n",
        "    mean_original = original.mean()\n",
        "    mean_imputed = imputed.mean()\n",
        "    variance_original = original.var()\n",
        "    variance_imputed = imputed.var()\n",
        "\n",
        "    consistency_df = pd.DataFrame({\n",
        "        'Mean_Original': mean_original,\n",
        "        'Mean_Imputed': mean_imputed,\n",
        "        'Variance_Original': variance_original,\n",
        "        'Variance_Imputed': variance_imputed\n",
        "    })\n",
        "\n",
        "    print(\"Consistency Check (Mean and Variance):\")\n",
        "    print(consistency_df)\n",
        "\n",
        "check_consistency(df_parameters, df_filled_scaled)"
      ],
      "metadata": {
        "id": "17rZG_4mbmdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ks_test(original, imputed):\n",
        "    ks_results = {}\n",
        "    for col in original.columns:\n",
        "        ks_stat, p_value = ks_2samp(original[col].dropna(), imputed[col])\n",
        "        ks_results[col] = {'KS Statistic': ks_stat, 'p-value': p_value}\n",
        "\n",
        "    ks_df = pd.DataFrame(ks_results).T\n",
        "    print(\"Kolmogorov-Smirnov Test Results:\")\n",
        "    print(ks_df)\n",
        "    return ks_df\n",
        "\n",
        "ks_test_results = ks_test(df_parameters, df_filled_scaled)"
      ],
      "metadata": {
        "id": "GCyG2X4sbrBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correlation_analysis(original, imputed):\n",
        "    corr_original = original.corr()\n",
        "    corr_imputed = imputed.corr()\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.heatmap(corr_original, annot=True, cmap='coolwarm')\n",
        "    plt.title('Original Data Correlation')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.heatmap(corr_imputed, annot=True, cmap='coolwarm')\n",
        "    plt.title('Imputed Data Correlation')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "correlation_analysis(df_parameters, df_filled_scaled)"
      ],
      "metadata": {
        "id": "urqdQi74btu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled_scaled.to_csv(\"filled_with_knn.csv\", index=False)"
      ],
      "metadata": {
        "id": "QF5WQbq4c8dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5LbWgOLMdD8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}